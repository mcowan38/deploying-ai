{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6711f7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will start with a discussion of APIs, set up our Jupyter notebook, and then conquer the LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe804593",
   "metadata": {},
   "source": [
    "# Application Programming Interfaces\n",
    "\n",
    "An Application Programming Interface (API) is a mechanism that enables two software components to communicate with each other using a set of definitions and protocols. ([AWS](https://aws.amazon.com/what-is/api/))\n",
    "\n",
    "+ An *application* is any software with a distinct function. \n",
    "+ An *interface* can be seen as a contract between two applications that specifies how they will communicate with each other.\n",
    "\n",
    "![](./img/01_api.svg)\n",
    "\n",
    "## Types of APIs\n",
    "\n",
    "There are four ways an API can work:\n",
    "\n",
    "### SOAP APIs\n",
    "\n",
    "+ Simple Object Access Protocol. \n",
    "+ Client and server exchange using XML. \n",
    "+ Popular in the past, but less flexible than more modern alternatives.\n",
    "\n",
    "### RPC APIs\n",
    "\n",
    "+ Remote Procedural Calls.\n",
    "+ Client completes a function (or procedure) on the server. \n",
    "+ The server sends the output back to the client.\n",
    "\n",
    "### Websocket APIs\n",
    "\n",
    "+ Uses JSON objects to pass data.\n",
    "+ Supports two-way communication between client app and server.\n",
    "+ Server can send callback messages to connected clients, making it more efficient than REST API.\n",
    "\n",
    "### REST APIs\n",
    "\n",
    "+ Representational State Transfer.\n",
    "+ Most popular and flexible APIs found today.\n",
    "+ Client sends a request to the server as data.\n",
    "+ Server uses this client input to start internal functions and returns output data to the client.\n",
    "+ Defines a set of functions (e.g., GET, PUT, DELETE) that clients can use to access server data.\n",
    "+ Clients and servers exchange data using HTTP.\n",
    "+ REST APIs are stateless: servers do not save client data between requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f299413",
   "metadata": {},
   "source": [
    "## API Endpoints\n",
    "\n",
    "API endpoints are the final touchpoints in the API communication system. API endpoints can be server URLs, services, and other specific digital locations where information is sent and received between systems.\n",
    "\n",
    "Two critical aspects about API Endpoints are:\n",
    "\n",
    "1. Security: API endpoints make the system vulnerable to attack.\n",
    "2. Performance: API endpoints, particularly high-traffic ones, can cause bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c18359",
   "metadata": {},
   "source": [
    "## OpenAI's API\n",
    "\n",
    "+ The OpenAI API is a helpful starting point for building AI applications.\n",
    "+ The API provides endpoints for various services, for example:\n",
    "\n",
    "    - Responses API: https://api.openai.com/v1/responses\n",
    "    - Conversations API: https://api.openai.com/v1/conversations\n",
    "    - Videos API: https://api.openai.com/v1/videos\n",
    "    - Embeddings API: https://api.openai.com/v1/embeddings\n",
    "    - Eval API: https://api.openai.com/v1/evals\n",
    "\n",
    "+ As well, OpenAI offers [Software Development Kits (SDK)](https://platform.openai.com/docs/libraries#install-an-official-sdk) for their APIs. These SDKs allow us to interact with the API with Python functions instead of forming URLs and using tools like curl. SDKs are available for Python, JavaScript, .NET, Java, and Go.\n",
    "+ The API is not the only interface to OpenAI's models and services, for example, \n",
    "\n",
    "    - Web apps are used to interact with GPT models via a chat client, [ChatGPT](https://chatgpt.com/).\n",
    "    - Developers can create agentic workflows using [Agent Builder](https://platform.openai.com/agent-builder) a no-code/low-code alternative to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079138e",
   "metadata": {},
   "source": [
    "# Authentication\n",
    "\n",
    "+ Authentication is the process of verifying a user's or system's identity.\n",
    "+ Authentication (who you are) is generally paired with authorization (what you can do). \n",
    "+ Authenticating to the OpenAI service is done through an SSH Key, Secret Key, or API Key.\n",
    "+ Details can be found in [OpenAI's API Documentation](https://platform.openai.com/docs/api-reference/introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad26e",
   "metadata": {},
   "source": [
    "## Obtaining and Using API Keys\n",
    "\n",
    "+ You can obtain OpenAI API Keys from [this page](https://platform.openai.com/api-keys).\n",
    "+ Consider the following [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety):\n",
    "\n",
    "    1. Always use a unique API key for each team member on your account. \n",
    "    2. Never deploy your key in client-side environments like browsers or mobile apps.\n",
    "    3. Never commit your key to your repository.\n",
    "    4. Use Environment Variables in place of your API key.\n",
    "    5. Use a Key Management Service.\n",
    "    6. Monitor your account usage and rotate your keys when needed.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712f76e",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Setup\n",
    "\n",
    "In this section, we discuss a few preliminaries that will be useful throughout our lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe751dbe",
   "metadata": {},
   "source": [
    "## Update System Path\n",
    "\n",
    "Add the folder `./05_src/` to the system path. This allows us to reuse our modules in this notebook. We can also avoid duplication as we build on code we have written before.\n",
    "\n",
    "The next cell imports the sys module and appends a relative path ('../../05_src/') to the system path. This allows Python to locate and import custom modules from that directory in subsequent cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../05_src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e30d88",
   "metadata": {},
   "source": [
    "## Use a Logger\n",
    "\n",
    "- A logger affords observability and retains your logs.\n",
    "- Log formats are customizable, and you can include items like timestamp, module, function, line number, and so on.\n",
    "- Log level is also customizable:\n",
    "\n",
    "    + INFO for regular operations.\n",
    "    + DEBUG for development.\n",
    "    + ERROR and WARNING will be logged.\n",
    "\n",
    "- Useful documents on logging:\n",
    "\n",
    "    - [Python logging library](https://docs.python.org/3/library/logging.html).\n",
    "    - [Real Python: Logging](https://realpython.com/python-logging/).\n",
    "    - [The Hitchhiker's Guide to Python: Logging](https://docs.python-guide.org/writing/logging/).\n",
    "\n",
    "The code cell below imports the `get_logger()` function from the `utils.logger` module. Notice that this module is located in ./05_src/utils/logger.py. We can directly load the module because we added the source folder (05_src) to our system path above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bd2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import get_logger\n",
    "_logs = get_logger(__name__, log_dir='../../06_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da49a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 17:16:02,891, 999434666.py, 1, INFO, This is a log message.\n"
     ]
    }
   ],
   "source": [
    "_logs.info('This is a log message.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0942",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "+ Environment variables are stored in the operating system environment and not declared within the application itself.\n",
    "+ They are convenient variables for storing settings such as file locations, directories, operational parameters, and log levels, among others.\n",
    "+ They can also store secrets (API keys, passwords, etc.)\n",
    "\n",
    "### Dotenv and .env\n",
    "\n",
    "We can set environment variables in the terminal window, but we can also use a convenient library called [`python-dotenv`](https://pypi.org/project/python-dotenv/).\n",
    "\n",
    "From a Python module, you can call this functionality as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc7085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../05_src/.secrets') # loads secrets file as environment file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b07fa",
   "metadata": {},
   "source": [
    "However, from a Jupyter notebook, you would usually use something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76030d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook use magic commands (%)\n",
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.env\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34caf53c",
   "metadata": {},
   "source": [
    "We can obtain the value of an environment variable using [`os.getenv()`](https://docs.python.org/3/library/os.html#os.getenv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b8d22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFO'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv('LOG_LEVEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ce15f",
   "metadata": {},
   "source": [
    "### About .secrets\n",
    "\n",
    "The .secrets file is similar to .env in that it contains key-value pairs intended to be set as environment variables. However, we segregate certain variables, the secrets, into a special file which is then ignored by .git by adding it to .gitignore.\n",
    "\n",
    "A sample of the expected format of .secrets is .secrets.template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328dd79e",
   "metadata": {},
   "source": [
    "# Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed6301",
   "metadata": {},
   "source": [
    "We will use the [OpenAI Python API library](https://github.com/openai/openai-python?tab=readme-ov-file) as our main tool to communicate with OpenAI's API.\n",
    "\n",
    "The code cell below makes a first call to the Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fecd195",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'message': 'Forbidden'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      2\u001b[39m client = OpenAI(base_url=\u001b[33m'\u001b[39m\u001b[33mhttps://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      3\u001b[39m                 api_key=\u001b[33m'\u001b[39m\u001b[33many value\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m                 default_headers={\u001b[33m\"\u001b[39m\u001b[33mx-api-key\u001b[39m\u001b[33m\"\u001b[39m: os.getenv(\u001b[33m'\u001b[39m\u001b[33mAPI_GATEWAY_KEY\u001b[39m\u001b[33m'\u001b[39m)})\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mHello world!\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.output_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DSI/deploying-ai/deploying-ai-env/lib/python3.11/site-packages/openai/resources/responses/responses.py:828\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    793\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    826\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    827\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DSI/deploying-ai/deploying-ai-env/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DSI/deploying-ai/deploying-ai-env/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'message': 'Forbidden'}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = 'Hello world!'\n",
    "    \n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed011ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795fb577",
   "metadata": {},
   "source": [
    "There are several things happening in this code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb68e77",
   "metadata": {},
   "source": [
    "1. Load the OpenAI library and instantiate a client object. The client object handles authentication, API calls, request/response handling, and error handling. In particular, it will look for an API key in an environment variable called `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62325d02",
   "metadata": {},
   "source": [
    "Alternatively, use an API Gateway by providing the parameters `base_url` and appropriate headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5219ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05951acf",
   "metadata": {},
   "source": [
    "2. We create an API call and store the result in the variable `response`. Notice that the call specifies the model that we want to use, as well as an input. This is a simple call, the [responses API can handle more complex calls](https://platform.openai.com/docs/api-reference/responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = 'Hello world!',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844795a7",
   "metadata": {},
   "source": [
    "3. Print out `output_text` from the response. The repsonse object will contain an attribute called `output` (a list) that contains content (another list) and the content contains text. Below we show these relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4094417",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfacf829",
   "metadata": {},
   "source": [
    "In the sample code, we used a convenience attribute called `output_text` that includes a concatenation of the text in all content and all output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f1482",
   "metadata": {},
   "source": [
    "**Note**: From the [documentation](https://platform.openai.com/docs/guides/text?api-mode=responses) we know that,\n",
    "\n",
    "> The output array often has more than one item in it! It can contain tool calls, data about reasoning tokens generated by reasoning models, and other items. It is not safe to assume that the model's text output is present at output[0].content[0].text.\n",
    ">\n",
    "> Some of our official SDKs include an output_text property on model responses for convenience, which aggregates all text outputs from the model into a single string. This may be useful as a shortcut to access text output from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6036d3c",
   "metadata": {},
   "source": [
    "Finally, we show the JSON-serialized version of the response object. The response object offers two methods to obtain JSON and dictionary versions of the repsonse: `repsonse.to_json()` and `response.model_dump()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795e95f",
   "metadata": {},
   "source": [
    "### About the Response API\n",
    "\n",
    "The implementation above could have been completed with another API, for example, Chat. However,  the [documentation](https://platform.openai.com/docs/api-reference/responses) states that the Responses API is:\n",
    "\n",
    "> OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
